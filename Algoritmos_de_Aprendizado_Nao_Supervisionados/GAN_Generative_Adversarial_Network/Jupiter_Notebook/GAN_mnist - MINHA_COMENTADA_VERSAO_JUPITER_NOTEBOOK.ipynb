#!/usr/bin/env python
# coding: utf-8

# In[237]:


import tensorflow as tf #importando o tensorflow
tf.reset_default_graph() #para resetar ou seja limpar as variaveis
from tensorflow.examples.tutorials.mnist import input_data #baixando a biblioteca mnist
mnist = input_data.read_data_sets('mnist/', one_hot = True) #importando o dataset minist


# In[238]:


import matplotlib.pyplot as plt #importando o matplot
#get_ipython().run_line_magic('matplotlib', 'inline')   COM ESSA LINHA SO FUNCIONA NO JUPITER NOTEBOOK...
plt.imshow(mnist.train.images[0].reshape(28,28), cmap = 'Greys') #plotando a imagem que esta na coluna [0], no caso essa imagem e o numero 7


# In[239]:


mnist.train.images[0] #notamos que o numero 7 ele é o conjunto de numeros a baixo... Ou seja vamos ensinar o gerador que o conjunto de numeros a baixo forma algo parecido com o numero 7... Entao o gerador vaicomecar a gerar numeros aleartorios ate que forme algum numero como o 7 ou outro numero qualquer... OPS CADA CONJUNTO DE NUMERO DESSES SEPARADO POR VIRGULA REPRESENTA UM PIXEL NA IMAGEM... COMO A IMAGEM E NA RESOLUCAO 28*28 ENTAO TEMOS 784 CONJUNTO DE NUMEROS


# In[240]:


import numpy as np #imporando numpy
imagem1 = np.arange(0,784).reshape(28,28) #gerando 784 numeros(porque a imagem e na resolucao 28*28...) entao ele vai gerar 784 conjunto de numeros um conjunto representando cada pixel
imagem1 #os numeros sao essa imagem
plt.imshow(imagem1) #eles formam essa imagem usando do 0 ate o 784


# In[241]:


imagem2 = np.random.normal(size = 784).reshape(28,28) #agora gerando784 numeros tambem, mas de forma randomica
plt.imshow(imagem2) #plotando a imagem...


# In[242]:


ruido_ph = tf.placeholder(tf.float32, [None, 100])#gerando numeros aleartorios... No caso 100 entradas de numeros aleatorios


# In[243]:


def gerador(ruido, reuse = None): #criando gerador... comando reuse para reusar variaveis
    with tf.variable_scope('gerador', reuse = reuse): #escopo das variaveis... para definir variaveis com numeros em lote
        # 100 entrada~> 128 segunda camada oculta ~> 128 terceira camada oculta ~> 784 camada de saida
        camada_oculta1 = tf.nn.relu(tf.layers.dense(inputs = ruido, units = 128)) #fazendo a ligacao com os 100 valores de ruido (ou seja numeros aleartorios. OS RUIDOS SAO OS NUMEROS ALEATORIOS)... Fazendo a ligacao deles com a primeira camada oculta de 128 neuronios
        camada_oculta2 = tf.nn.relu(tf.layers.dense(inputs = camada_oculta1, units = 128)) #camada oculta 2... Assim como a primeica camada oculta ela tambem usa a funcao RELU
        camada_saida = tf.layers.dense(inputs = camada_oculta2, units = 784, activation = tf.nn.tanh)#camada de saida... O inputs dela e a camada oculta2, pois os dados que ela vai receber sao os dados da camada oculta2... E essa camada de saida tem 784 neurnios... FUNCAO DE ATIVACAO TANGENTE, POIS ELA GERA VALORES ENTRE -1 E 1
        return camada_saida


# In[244]:


imagens_reais_ph = tf.placeholder(tf.float32, [None, 784]) #vai receber como entrada uma imagem e ele vai ter que dizer se é uma imagem que é um numero ou nao


# In[245]:


def discriminador(X, reuse = None): #X sao os atributos previsores da imagem
    with tf.variable_scope('discriminador', reuse = reuse):
        #784 (imagem de entrada 28*28 = 784) ~> primeica camada oculta com 128 neuronios~> segunda camada oculta com 128 neuronios~> camada de saida com 1 neuronio... Que vai dizer se a imagem e um numero ou nao
        camada_oculta1 = tf.nn.relu(tf.layers.dense(inputs = X, units = 128)) #camada densa com ativacao relu que a entrada e o X ou seja os atributos previsores das imagens, e 128 neuronios
        camada_oculta2 = tf.nn.relu(tf.layers.dense(inputs = camada_oculta1, units = 128)) #camada oculta 2 em que a entrada dos dados sao os dados da camada oculta 1... com 128 neuronios
        logits = tf.layers.dense(camada_oculta2, units = 1) #camada de saida... ela recebe os dados da segunda camada oculta 2... que tem 1 neuronios e diz a probabilidade de ser ou a imagem de um numero
        return logits


# In[246]:


logits_imagens_reais = discriminador(imagens_reais_ph) ##vamos chamar a funcao descriminador, vmaos passar os parameetros as imagens reais os placeholdes... e ele vai retornar para esse forma os logits
logits_imagens_ruido = discriminador(gerador(ruido_ph), reuse = True) #o essa linha chamando o logits novamente vai comparar as imagens reais que sao as imagens que realmente sao de numeros, com as imagens que saõ ruidos... ou seja as imagens que foram geradas pelo o gerador

erro_discriminador_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = logits_imagens_reais,
                                                                                labels = tf.ones_like(logits_imagens_reais) * (0.9))) #calculo de erro para as imagens reais
erro_discriminador_ruido = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = logits_imagens_ruido,
                                                                                  labels = tf.zeros_like(logits_imagens_ruido))) #calculo de erro paraas imagens geradas, ou seja as imagens ruido
erro_discriminador = erro_discriminador_real + erro_discriminador_ruido #erro total do discriminador... Depois sera otimizada com o otimizador

erro_gerador = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = logits_imagens_ruido,
                                                                      labels = tf.ones_like(logits_imagens_ruido))) #erro para rede neural do gerador


# In[247]:


variaveis = tf.trainable_variables() #essa funcao vai retornar quais sao as variaveis que sao passiveis de otimizacao
variaveis #as variaveis que estao prontas para o treinamento


# In[249]:


variaveis_discriminador = [v for v in variaveis if 'discriminador' in v.name] #essa funcao vai pegar as variaveis que tem o nome de discriminador na lista acima
print([v.name for v in variaveis_discriminador]) 


# In[251]:


variaveis_gerador = [v for v in variaveis if 'gerador' in v.name]#essa funcao vai pegar as variaveis que tem o nome de gerador na lista acima
print([v.name for v in variaveis_gerador])


# In[252]:


treinamento_discriminador = tf.train.AdamOptimizer(learning_rate = 0.001).minimize(erro_discriminador,
                                                                                  var_list = variaveis_discriminador) #otimizacao das variaveis do discriminizador... var_list = variaveis_discriminador pq ele quer otimizar apenas as variaveis do discriminador
treinamento_gerador = tf.train.AdamOptimizer(learning_rate = 0.001).minimize(erro_gerador,
                                                                            var_list = variaveis_gerador) #otimizacao das variaveis do gerador... var_list = variaveis_gerador pq ele quer otimizar apenas as variaveis do gerador


# In[257]:


batch_size = 100 #100 em 100 registros
amostras_teste = [] #lista vazia, a cada etapa do treinamento um exemplo da imagem que foi gerada sera salva aqui... a medida que vai passando as epocas
with tf.Session() as sess:
    sess.run(tf.global_variables_initializer()) #iniciando as variaveis
    
    #ruido_teste = np.random.uniform(-1, 1, size = (1, 100))
    #amostra = sess.run(gerador(ruido_ph, True), feed_dict = {ruido_ph: ruido_teste}) #funcao geradora das imagens aleartorios atraves dos numeros que estao no ruido_teste
    
    #batch = mnist.train.next_batch(100)
    #imagens_batch = batch[0].reshape((100, 784))
    #imagens_batch = imagens_batch * 2 -1
    #r = sess.run(discriminador(imagens_reais_ph, True), feed_dict = {imagens_reais_ph: imagens_batch}) chamando o discriminador que recebem as imagens do placeholder
    #r2 = sess.run(tf.nn.sigmoid(r)) #por meio da funcao sigmoid ele mostra a probabilidade de ser um digito manuescrito
    #ex = tf.constant([[1,2],[3,4]])
    #print(sess.run(tf.ones_like(ex)))
    
    for epoca in range(2): ## O PADRAO É (50) SO QUE COMO DEMORA MUITO EU COLOQUEI 2
        numero_batches = mnist.train.num_examples // batch_size #550 batchs pq... sao 55000 imagens no mnist train... divididas por batch_size que é 100... entao da 550 batchs e dentro de cada 1 teremos 100 imagens
        for i in range (numero_batches): #numero de batchs
            batch = mnist.train.next_batch(batch_size) # #inicia os testes - SE EU COLOCAR UM NUMERO DE 0 A 100 NO BATCH EU CONSIGO VER COMO FICOU O TREINAMENTO NAQELE NUMERO DE VEZ
            imagens_batch = batch[0].reshape((100, 784)) #100 imagens 784 pixels
            imagens_batch = imagens_batch * 2 - 1 #como estamos usando uma funcao de ativacao tangernte hiperbolica... Nessa linha estamos convertendo as imagens de 0 e 1 para -1 e 1
            
            batch_ruido = np.random.uniform(-1, 1, size = (batch_size, 100)) #100 para ser todas imagens 
            
            _, custod = sess.run([treinamento_discriminador, erro_discriminador],
                                 feed_dict = {imagens_reais_ph: imagens_batch, ruido_ph: batch_ruido}) #pegar o erro do discriminador, com o feed_dict da imagens reais ph... e passar isso para o ruido_ph
            _, custog = sess.run([treinamento_gerador, erro_gerador], feed_dict = {ruido_ph: batch_ruido}) #treinamento do gerador alimentado com o ruido_ph
            
            print('época:' + str(epoca + 1) + 'erro D: ' +str(custod) + 'erro G: ' + str(custog)) #visualizar informacoes
            
            ruido_teste = np.random.uniform(-1 , 1, size = (1, 100)) #iniciando a geracao de 1 registro e 100 colunas de numeros aleartorios entre -1 e 1
            imagem_gerada = sess.run(gerador(ruido_ph, reuse = True), feed_dict = {ruido_ph: ruido_teste}) #aqui esta o resultado da imagem gerada
            amostras_teste.append(imagem_gerada) #iniciar os testes e gerar a imagem
            


# In[116]:


amostra.shape #1 registro e 784 pixels - ou seja 1 imagem com 784 pixels


# In[117]:


plt.imshow(amostra.reshape(28,28))#imagem gerada aleartoriamente com os numeros aleartorios


# In[118]:


batch = mnist.train.next_batch(100) #para visualizar os resultado do que esta na posicao 100 do batch
batch[0].shape
imagens_batch = batch[0].reshape((100, 784))


# In[119]:


imagens_batch.shape #nao entendi, mas nao e importante


# In[120]:


imagens_batch[0] #os pixels na posicao 0 do batch.... Para formar imagem


# In[121]:


imagens_batch = imagens_batch * 2 - 1 #como estamos usando uma funcao de ativacao tangernte hiperbolica... Nessa linha estamos convertendo as imagens de 0 e 1 para -1 e 1
imagens_batch[0]


# In[122]:


r.shape #100 registros e 1 coluna


# In[123]:


r #variavel R mostra a que esta no descriminador... o descriminador no qual essa variavel recebe os dados ele ta desativado... pq ele ta comentado


# In[124]:


r2 #mostra a probabilidade de ser um digito manusescrito em cada linha


# In[259]:


amostras_teste


# In[272]:


plt.imshow(amostras_teste[999].reshape(28,28), cmap = 'Greys')


# In[ ]:




